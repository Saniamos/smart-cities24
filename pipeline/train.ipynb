{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run at: 12.04.2024 17:18:19\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(\"Run at:\", datetime.now().strftime(\"%d.%m.%Y %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yale1/miniconda3/envs/smart-cities/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Enable interactive plot\n",
    "#@formatter:off\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#@formatter:on\n",
    "\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "\n",
    "import lightning as pl\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.callbacks import TQDMProgressBar\n",
    "\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "\n",
    "from run import path_resolution, train, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "debug = True\n",
    "dry_run = False\n",
    "num_worker = 5\n",
    "computease = False\n",
    "\n",
    "# lib = \"Sequence\"\n",
    "# params = \"hp_default\"\n",
    "# data = \"RSO_LModule_Seq\"\n",
    "\n",
    "lib = \"DenseNet\"\n",
    "params = \"hp_dropna\"\n",
    "# params = \"hp_default\"\n",
    "data = \"RSO_LModule\"\n",
    "\n",
    "# lib = \"T_Sequence\"\n",
    "# params = \"hp_default\"\n",
    "# data = \"T_LModule_Seq\"\n",
    "\n",
    "\n",
    "# data = \"RSO_LModule_Seq\"\n",
    "# lib = \"Sequence_pretrained\"\n",
    "# # params = \"hp_default\"\n",
    "# params = \"hp_smaller\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "interm_path = '_debug' if debug else ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- rsync --\n",
      "Calling: rsync -av /share/temp/yhartmann/smart-cities-journal-based-on-jonahs-ma/data/ /share/data/yhartmann/data/ma-jonah/\n",
      "sending incremental file list\n",
      "\n",
      "sent 2,937 bytes  received 31 bytes  5,936.00 bytes/sec\n",
      "total size is 20,378,829,669  speedup is 6,866,182.50\n",
      " -- rsync finished --\n",
      "\n",
      "Base path: /share/data/yhartmann/data/ma-jonah/\n"
     ]
    }
   ],
   "source": [
    "# path resolution\n",
    "base_path = path_resolution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_checkpoint_path: /share/temp/yhartmann/smart-cities-journal-based-on-jonahs-ma/pipeline/checkpoints_debug/DenseNet.hp_dropna.ckpt\n"
     ]
    }
   ],
   "source": [
    "# resolve checkpoints\n",
    "checkpoint_path = Path(f\"./checkpoints{interm_path}/\").resolve()\n",
    "checkpoint_path.mkdir(parents=True, exist_ok=True)\n",
    "model_checkpoint_path = f\"{str(checkpoint_path / lib)}.{params}.ckpt\"\n",
    "print(f\"model_checkpoint_path: {model_checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nn module\n",
    "NNModule = importlib.import_module(f\"models.{lib}\")\n",
    "\n",
    "# resolve hyperparameters\n",
    "hyper_params = getattr(NNModule, params)\n",
    "if debug:\n",
    "    hyper_params['trainer_params']['max_epochs'] = 2\n",
    "    # hyper_params['trainer_params']['profiler'] = 'simple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-12 17:18:23,313 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmpx4pkiv17\n",
      "2024-04-12 17:18:23,315 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmpx4pkiv17/_remote_module_non_scriptable.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yale1/miniconda3/envs/smart-cities/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'loss_function' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_function'])`.\n"
     ]
    }
   ],
   "source": [
    "model = NNModule.NeuralNetwork(model_params=hyper_params['model_params'],\n",
    "                    optimizer=hyper_params['optimizer'],\n",
    "                    loss_function=hyper_params['loss_function'],\n",
    "                    optimizer_params=hyper_params['optimizer_params'],\n",
    "                    scheduler_params=hyper_params['scheduler_params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# construct data module\n",
    "DLModule = getattr(importlib.import_module(f\"datasets.{data}\"), data)\n",
    "data_module = DLModule(data_dir=base_path, \n",
    "    # n_jobs=1, \n",
    "    n_jobs=num_worker, \n",
    "    debug=debug, \n",
    "    **hyper_params['data_params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 480, 848)\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─DenseNet: 1-1                          [-1, 63]                  --\n",
      "|    └─Sequential: 2-1                   [-1, 1024, 15, 26]        --\n",
      "|    |    └─Conv2d: 3-1                  [-1, 64, 240, 424]        3,136\n",
      "|    |    └─BatchNorm2d: 3-2             [-1, 64, 240, 424]        128\n",
      "|    |    └─ReLU: 3-3                    [-1, 64, 240, 424]        --\n",
      "|    |    └─MaxPool2d: 3-4               [-1, 64, 120, 212]        --\n",
      "|    |    └─_DenseBlock: 3-5             [-1, 256, 120, 212]       335,040\n",
      "|    |    └─_Transition: 3-6             [-1, 128, 60, 106]        33,280\n",
      "|    |    └─_DenseBlock: 3-7             [-1, 512, 60, 106]        919,680\n",
      "|    |    └─_Transition: 3-8             [-1, 256, 30, 53]         132,096\n",
      "|    |    └─_DenseBlock: 3-9             [-1, 1024, 30, 53]        2,837,760\n",
      "|    |    └─_Transition: 3-10            [-1, 512, 15, 26]         526,336\n",
      "|    |    └─_DenseBlock: 3-11            [-1, 1024, 15, 26]        2,158,080\n",
      "|    |    └─BatchNorm2d: 3-12            [-1, 1024, 15, 26]        2,048\n",
      "|    └─Linear: 2-2                       [-1, 63]                  64,575\n",
      "==========================================================================================\n",
      "Total params: 7,012,159\n",
      "Trainable params: 7,012,159\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 2.85\n",
      "==========================================================================================\n",
      "Input size (MB): 1.55\n",
      "Forward/backward pass size (MB): 232.85\n",
      "Params size (MB): 26.75\n",
      "Estimated Total Size (MB): 261.15\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─DenseNet: 1-1                          [-1, 63]                  --\n",
       "|    └─Sequential: 2-1                   [-1, 1024, 15, 26]        --\n",
       "|    |    └─Conv2d: 3-1                  [-1, 64, 240, 424]        3,136\n",
       "|    |    └─BatchNorm2d: 3-2             [-1, 64, 240, 424]        128\n",
       "|    |    └─ReLU: 3-3                    [-1, 64, 240, 424]        --\n",
       "|    |    └─MaxPool2d: 3-4               [-1, 64, 120, 212]        --\n",
       "|    |    └─_DenseBlock: 3-5             [-1, 256, 120, 212]       335,040\n",
       "|    |    └─_Transition: 3-6             [-1, 128, 60, 106]        33,280\n",
       "|    |    └─_DenseBlock: 3-7             [-1, 512, 60, 106]        919,680\n",
       "|    |    └─_Transition: 3-8             [-1, 256, 30, 53]         132,096\n",
       "|    |    └─_DenseBlock: 3-9             [-1, 1024, 30, 53]        2,837,760\n",
       "|    |    └─_Transition: 3-10            [-1, 512, 15, 26]         526,336\n",
       "|    |    └─_DenseBlock: 3-11            [-1, 1024, 15, 26]        2,158,080\n",
       "|    |    └─BatchNorm2d: 3-12            [-1, 1024, 15, 26]        2,048\n",
       "|    └─Linear: 2-2                       [-1, 63]                  64,575\n",
       "==========================================================================================\n",
       "Total params: 7,012,159\n",
       "Trainable params: 7,012,159\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 2.85\n",
       "==========================================================================================\n",
       "Input size (MB): 1.55\n",
       "Forward/backward pass size (MB): 232.85\n",
       "Params size (MB): 26.75\n",
       "Estimated Total Size (MB): 261.15\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data_module.data_shape)\n",
    "summary(model, data_module.data_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use tensor cores\n",
    "if computease:\n",
    "    torch.set_float32_matmul_precision('medium')\n",
    "    print('Using Tensor Cores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(logger=TensorBoardLogger(checkpoint_path, name=lib, version=params), \n",
    "                fast_dev_run=dry_run,\n",
    "                default_root_dir=checkpoint_path, \n",
    "                callbacks=[EarlyStopping(**hyper_params[\"early_stopping_params\"]), TQDMProgressBar(refresh_rate=1 if debug else 100)],\n",
    "                **hyper_params['trainer_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 17:18:27] offline tracker init\n",
      "[codecarbon INFO @ 17:18:27] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 17:18:27] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 17:18:27] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 17:18:27] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 17:18:27] No CPU tracking mode found. Falling back on CPU constant mode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 17:18:28] We saw that you have a Intel(R) Xeon(R) Gold 5118 CPU @ 2.30GHz but we don't know it. Please contact us.\n",
      "[codecarbon INFO @ 17:18:28] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 5118 CPU @ 2.30GHz\n",
      "[codecarbon INFO @ 17:18:28] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 17:18:28]   Platform system: Linux-5.4.0-135-generic-x86_64-with-glibc2.31\n",
      "[codecarbon INFO @ 17:18:28]   Python version: 3.10.14\n",
      "[codecarbon INFO @ 17:18:28]   CodeCarbon version: 2.3.5\n",
      "[codecarbon INFO @ 17:18:28]   Available RAM : 251.554 GB\n",
      "[codecarbon INFO @ 17:18:28]   CPU count: 48\n",
      "[codecarbon INFO @ 17:18:28]   CPU model: Intel(R) Xeon(R) Gold 5118 CPU @ 2.30GHz\n",
      "[codecarbon INFO @ 17:18:28]   GPU count: 1\n",
      "[codecarbon INFO @ 17:18:28]   GPU model: 1 x NVIDIA GeForce RTX 2080 Ti\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-12 17:18:28,234 - run - INFO - ==== TRAIN ================================================\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─DenseNet: 1-1                          [-1, 63]                  --\n",
      "|    └─Sequential: 2-1                   [-1, 1024, 15, 26]        --\n",
      "|    |    └─Conv2d: 3-1                  [-1, 64, 240, 424]        3,136\n",
      "|    |    └─BatchNorm2d: 3-2             [-1, 64, 240, 424]        128\n",
      "|    |    └─ReLU: 3-3                    [-1, 64, 240, 424]        --\n",
      "|    |    └─MaxPool2d: 3-4               [-1, 64, 120, 212]        --\n",
      "|    |    └─_DenseBlock: 3-5             [-1, 256, 120, 212]       335,040\n",
      "|    |    └─_Transition: 3-6             [-1, 128, 60, 106]        33,280\n",
      "|    |    └─_DenseBlock: 3-7             [-1, 512, 60, 106]        919,680\n",
      "|    |    └─_Transition: 3-8             [-1, 256, 30, 53]         132,096\n",
      "|    |    └─_DenseBlock: 3-9             [-1, 1024, 30, 53]        2,837,760\n",
      "|    |    └─_Transition: 3-10            [-1, 512, 15, 26]         526,336\n",
      "|    |    └─_DenseBlock: 3-11            [-1, 1024, 15, 26]        2,158,080\n",
      "|    |    └─BatchNorm2d: 3-12            [-1, 1024, 15, 26]        2,048\n",
      "|    └─Linear: 2-2                       [-1, 63]                  64,575\n",
      "==========================================================================================\n",
      "Total params: 7,012,159\n",
      "Trainable params: 7,012,159\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 2.85\n",
      "==========================================================================================\n",
      "Input size (MB): 1.55\n",
      "Forward/backward pass size (MB): 232.85\n",
      "Params size (MB): 26.75\n",
      "Estimated Total Size (MB): 261.15\n",
      "==========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-12 17:18:28.661830: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-12 17:18:28.706380: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-12 17:18:29.505868: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "QUEUEING TASKS | : 100%|██████████| 5/5 [00:00<00:00, 1886.78it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 5/5 [00:04<00:00,  1.01it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 5/5 [00:00<00:00, 35187.11it/s]\n",
      "/home/yale1/miniconda3/envs/smart-cities/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:653: Checkpoint directory /share/temp/yhartmann/smart-cities-journal-based-on-jonahs-ma/pipeline/checkpoints_debug/DenseNet/hp_dropna/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-12 17:18:35,145 - run - ERROR - CUDA error: device kernel image is invalid\n",
      "CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yale1/miniconda3/envs/smart-cities/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/home/yale1/miniconda3/envs/smart-cities/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/yale1/miniconda3/envs/smart-cities/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 963, in _run\n",
      "    self.strategy.setup(self)\n",
      "  File \"/home/yale1/miniconda3/envs/smart-cities/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 149, in setup\n",
      "    self.accelerator.setup(trainer)\n",
      "  File \"/home/yale1/miniconda3/envs/smart-cities/lib/python3.10/site-packages/lightning/pytorch/accelerators/cuda.py\", line 53, in setup\n",
      "    _clear_cuda_memory()\n",
      "  File \"/home/yale1/miniconda3/envs/smart-cities/lib/python3.10/site-packages/lightning/fabric/accelerators/cuda.py\", line 381, in _clear_cuda_memory\n",
      "    torch.cuda.empty_cache()\n",
      "  File \"/home/yale1/miniconda3/envs/smart-cities/lib/python3.10/site-packages/torch/cuda/memory.py\", line 125, in empty_cache\n",
      "    torch._C._cuda_emptyCache()\n",
      "RuntimeError: CUDA error: device kernel image is invalid\n",
      "CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/share/temp/yhartmann/smart-cities-journal-based-on-jonahs-ma/pipeline/run.py\", line 122, in train\n",
      "    trainer.fit(model, data_module)\n",
      "  File \"/home/yale1/miniconda3/envs/smart-cities/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/yale1/miniconda3/envs/smart-cities/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 68, in _call_and_handle_interrupt\n",
      "    trainer._teardown()\n",
      "  File \"/home/yale1/miniconda3/envs/smart-cities/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1010, in _teardown\n",
      "    self.strategy.teardown()\n",
      "  File \"/home/yale1/miniconda3/envs/smart-cities/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 537, in teardown\n",
      "    self.lightning_module.cpu()\n",
      "  File \"/home/yale1/miniconda3/envs/smart-cities/lib/python3.10/site-packages/lightning/fabric/utilities/device_dtype_mixin.py\", line 82, in cpu\n",
      "    return super().cpu()\n",
      "  File \"/home/yale1/miniconda3/envs/smart-cities/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 798, in cpu\n",
      "    return self._apply(lambda t: t.cpu())\n",
      "  File \"/home/yale1/miniconda3/envs/smart-cities/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/yale1/miniconda3/envs/smart-cities/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/yale1/miniconda3/envs/smart-cities/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/yale1/miniconda3/envs/smart-cities/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 664, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/yale1/miniconda3/envs/smart-cities/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 798, in <lambda>\n",
      "    return self._apply(lambda t: t.cpu())\n",
      "RuntimeError: CUDA error: device kernel image is invalid\n",
      "CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 17:18:35] \n",
      "Graceful stopping: collecting and writing information.\n",
      "Please wait a few seconds...\n",
      "[codecarbon INFO @ 17:18:35] Energy consumed for RAM : 0.000181 kWh. RAM Power : 94.33266592025757 W\n",
      "[codecarbon INFO @ 17:18:35] Energy consumed for all GPUs : 0.000105 kWh. Total GPU Power : 54.69078189695336 W\n",
      "[codecarbon INFO @ 17:18:35] Energy consumed for all CPUs : 0.000082 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:18:35] 0.000368 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:18:35] Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(model, trainer, data_module, model_checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 17:18:35] offline tracker init\n",
      "[codecarbon INFO @ 17:18:35] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 17:18:35] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 17:18:35] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 17:18:35] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 17:18:35] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon WARNING @ 17:18:36] We saw that you have a Intel(R) Xeon(R) Gold 5118 CPU @ 2.30GHz but we don't know it. Please contact us.\n",
      "[codecarbon INFO @ 17:18:36] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 5118 CPU @ 2.30GHz\n",
      "[codecarbon INFO @ 17:18:36] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 17:18:36]   Platform system: Linux-5.4.0-135-generic-x86_64-with-glibc2.31\n",
      "[codecarbon INFO @ 17:18:36]   Python version: 3.10.14\n",
      "[codecarbon INFO @ 17:18:36]   CodeCarbon version: 2.3.5\n",
      "[codecarbon INFO @ 17:18:36]   Available RAM : 251.554 GB\n",
      "[codecarbon INFO @ 17:18:36]   CPU count: 48\n",
      "[codecarbon INFO @ 17:18:36]   CPU model: Intel(R) Xeon(R) Gold 5118 CPU @ 2.30GHz\n",
      "[codecarbon INFO @ 17:18:36]   GPU count: 1\n",
      "[codecarbon INFO @ 17:18:36]   GPU model: 1 x NVIDIA GeForce RTX 2080 Ti\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-12 17:18:36,492 - run - INFO - ==== TEST ================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████| 1/1 [00:00<00:00, 2538.92it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 1/1 [00:01<00:00,  1.94s/it]\n",
      "COLLECTING RESULTS | : 100%|██████████| 1/1 [00:00<00:00, 8256.50it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 1/1 [00:00<00:00, 1037.68it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 1/1 [00:01<00:00,  1.94s/it]\n",
      "COLLECTING RESULTS | : 100%|██████████| 1/1 [00:00<00:00, 8525.01it/s]\n",
      "Restoring states from the checkpoint path at /share/temp/yhartmann/smart-cities-journal-based-on-jonahs-ma/pipeline/checkpoints_debug/DenseNet.hp_dropna.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-12 17:18:40,446 - run - ERROR - CUDA error: device kernel image is invalid\n",
      "CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Traceback (most recent call last):\n",
      "  File \"/share/temp/yhartmann/smart-cities-journal-based-on-jonahs-ma/pipeline/run.py\", line 137, in evaluate\n",
      "    res_dict[\"skeleton\"] = trainer.test(model, data_module, ckpt_path=checkpoint_path)\n",
      "  File \"/home/yale1/miniconda3/envs/smart-cities/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 754, in test\n",
      "    return call._call_and_handle_interrupt(\n",
      "  File \"/home/yale1/miniconda3/envs/smart-cities/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/home/yale1/miniconda3/envs/smart-cities/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 794, in _test_impl\n",
      "    results = self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/yale1/miniconda3/envs/smart-cities/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 956, in _run\n",
      "    self._checkpoint_connector._restore_modules_and_callbacks(ckpt_path)\n",
      "  File \"/home/yale1/miniconda3/envs/smart-cities/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py\", line 397, in _restore_modules_and_callbacks\n",
      "    self.resume_start(checkpoint_path)\n",
      "  File \"/home/yale1/miniconda3/envs/smart-cities/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py\", line 79, in resume_start\n",
      "    loaded_checkpoint = self.trainer.strategy.load_checkpoint(checkpoint_path)\n",
      "  File \"/home/yale1/miniconda3/envs/smart-cities/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 367, in load_checkpoint\n",
      "    torch.cuda.empty_cache()\n",
      "  File \"/home/yale1/miniconda3/envs/smart-cities/lib/python3.10/site-packages/torch/cuda/memory.py\", line 125, in empty_cache\n",
      "    torch._C._cuda_emptyCache()\n",
      "RuntimeError: CUDA error: device kernel image is invalid\n",
      "CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 17:18:40] \n",
      "Graceful stopping: collecting and writing information.\n",
      "Please wait a few seconds...\n",
      "[codecarbon INFO @ 17:18:40] Energy consumed for RAM : 0.000104 kWh. RAM Power : 94.33266592025757 W\n",
      "[codecarbon INFO @ 17:18:40] Energy consumed for all GPUs : 0.000058 kWh. Total GPU Power : 53.12845586426277 W\n",
      "[codecarbon INFO @ 17:18:40] Energy consumed for all CPUs : 0.000047 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:18:40] 0.000209 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:18:40] Done!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({}, {}, {})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, trainer, data_module, model_checkpoint_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
